---
title: "Neural Algebra and Consciousness"
categories: [Mathematics]
tags:
  - Mathematics
  - Neural Network
  - Consciousness
use_math: true
---

수식이 깨지는 경우 다음 [링크](https://jryoungwmath.notion.site/Neural-Algebra-and-Consciousness-69c459327b1140418355318d44d29e17)를 통해 접속하시면 됩니다.

# Neural Algebra and Consciousness

GPT의 열기가 뜨겁습니다. 지난 글에서도 GPT를 다루었지만, 이번 글에서는 GPT와 의식에 관한 뜨거운 논의에 대한 다른 관점을 보기 위해, 인공신경망이 의식을 가질 수 있는지를 살펴보도록 하겠습니다. 다분히 수학적인 내용들로 구성이 되어 있음을 미리 알립니다.

# Algebras and Combinators

$A$를 non-empty set이라고 하고 $h:A\to A$를 partial function이라고 하자. 함수 $h$의 graph $H$는 $H=\{(a\to b):b=h(a),a\in A\}$로 정의된다. 여기서 $(a\to b)$를 $(a,b)$대신 적은 것은 다분히 의도적이다.

집합간의 연산으로 간주해서, singular argument $\{a\}$에 대한 $H$의 application은

$$
H\cdot\{a\}=\{b:\exists x\in\{a\}.(x\to b)\in H\}
$$

이다. 즉, $h(a)$ 중 $H$에 들어가는 것으로 생각할 수 있다. 우리의 첫 번째 목표는 이를 일반화하는 것이다.

$A\neq\emptyset$, $n\in\mathbb{N}$이라고 하고 $G_n(A)$를 귀납적으로 다음처럼 정의하자: $G_0(A)=A$, $G_{n+1}(A)=G_n(A)\cup\{(\alpha\to h);\alpha\subseteq G_n(A),\alpha\text{ finite},b\in G_n(A)\}$. 그리고 $G(A)=\bigcup_{n\in\mathbb{N}} G_n(A)$로 정의하자. $M,N\subseteq G(A)$에 대해서

$$
M\cdot N=\{b:\exists\alpha\subseteq N,(a\to b)\in M\}
$$

로 정의한다. 이는 위에서 정의한 $\{a\}$에 대한 $H$의 application의 일반화이다.

### Definition

Graph algebra over $A$는 binary operation $\cdot$에 대해 닫혀있는 $G(A)$의 subset들의 모임이다.

### Representation Theorem

$\mathbb{A}=\langle A,\cdot\rangle$로 표현되는, binary operation $\cdot$이 있는 모든 algebra는 $A$에 대한 graph albgebra 중 하나와 isomorphic하다.

- proof)
    
    Algebraic structure $\mathbb{A}$의 carrier set $A$으로부터 생성되는 $G(A)$를 위처럼 정의하자. 그리고 $A$에서 $G(A)$의 power set으로 가는 함수 $f$를 다음처럼 recursive하게 정의하자:
    
    $$
    f(a)=\bigcup_if_i(a)
    $$
    
    이 때 $f_0(a)=\{a\}$, $f_{i+1}(a)=f_i(a)\bigcup\{\alpha\to y:\exists b\in A, b\in\alpha\subseteq f_i(b)\text{ and }y\in f_i(a\cdot b)\text{ and }\alpha\text{ finite}\}$로 두자. 먼저
    
    $$
    f(a)=f(b)
    $$
    
    라면 $\{a\}=f(a)\cap A = f(b)\cap A=\{b\}$이므로 $f(a)=f(b)$라면 $a=b$이다.
    
    이제 $f(a\cdot b)=f(a)\cdot f(b)$임을 보이자. 이를 보이기 위해
    
    $$
    \begin{align*}f(a)\cdot f(b)&=\{y:\exists a\subseteq f(b),\alpha\to y\in f(a)\}\\&=\{y:\exists\alpha\subseteq f(b)\exists\text{ minimal }i,\alpha\to y\in f_{i+1}(\alpha)\}\\&=\{y:\exists\alpha\subseteq f(b)\exists i\exists u,v\in A, au=v\text{ and }u\in \alpha\subseteq f_i(u)\text{ and } y\in f_i(v)\}\end{align*}
    $$
    
    인데 $u\in\alpha\subseteq f(b)\cap f_i(u)$이고 $u\in A$이므로 $u=b$ and $v=a\cdot b$임을 알고, 따라서
    
    $$
    \begin{align*}f(a)\cdot f(b)&=\{y:\exists\alpha\subseteq f(b)\exists i.b\in\alpha\subseteq f_i(b)\text{ and }y\in f_i(a\cdot b)\}\\&=\{y:\exists i.y\in f_i(a\cdot b)\}=\bigcup_if_i(a\cdot b)=f(a\cdot b)\end{align*}
    $$
    
    임을 안다. 따라서 $f$는 isomorphic embedding이다.
    

# The Brain as an Algebra

Alan Turing의 업적 이래로 artificial neural network(ANN)는 brain model로 대두되었고 딥러닝의 유행 덕에 이러한 학풍은 더욱 가속화되었다. 수많은 ANN 모델이 있지만 이들 하나하나에 집중하기보다는 전체적인 ANN을 포괄하는 설명법을 전개해보기로 한다.

Brain model은 directed graph로 생각할 수 있다. 각 edge는 neuron이라고 불리며, 이들은 discrete time에 fire하여 신호를 전달한다. 이 firing time은 $t\in\mathbb{Z}$로 표현된다. 뇌의 전체적 모델을 firing function $f(a,t)$로 논리 전개를 할 수 있는데, 이 때 $a$라는 neuron이 time $t$에 fire하면 1, 아니면 0의 값을 갖는 모델로 표현된다. 다른 말로 $f$를 firing law를 따르는 함수라고도 부른다. Neuron $b$의 firing law는 neuron $a_1,a_2,\cdots,a_k$ 들의 firing at $t_1,t_2\cdots,t_k$에 의해서 $b$가 fire되는지의 여부가 결정되며 이는 directed edge로 표현된다. 이 때 incoming edge들의 fire에 의한 신호들이 given threshold 이상이 되면 neuron $b$도 fire하고, 아니면 fire하지 않는다.

## The Brain Model

Directed graph $A$가 있다고 하고 이의 모든 node에서의 firing law를 모아 놓은 것을 $F(A)$라고 하자. 이들을 합쳐서 우리는 brain model이라고 하고 $\mathcal{A}$로 쓸 것이다. ($A$와 $\mathcal{A}$의 폰트가 다름에 주의하라.) Brain model은 $\mathcal{A}$의 firing history들에 다음 표기법을 건 것으로 주어진다:

$T$를 time interval, 즉 $T\subseteq\mathbb{Z}$라고 하자. Firing function $f:A\times T\to\{0,1\}$은 $\mathcal{A}$의 firing history를 구성한다. 이는 Directed graph $H(\mathcal{A},T)$로 주어지는데 이 때 node들은 $\langle a,t\rangle$로 주어지고, 이는 time $t$에서 neuron $a$가 fire하는지의 여부로 주어진다. Graph의 edge들은 firing $\langle a_1,t_1\rangle$, $\cdots$, $\langle a_k,t_k\rangle$들이 $\langle b,t\rangle$에 연결되어있는 형태이고, 이는 전자의 fireing들이 $\langle b,t\rangle$을 fire하는지로 주어지는 edge이다. 우리는 이를 다음처럼 쓰기도 할 것이다:

$$
[[\langle a_1,t_1\rangle,o,\langle a_2,t_2\rangle,o,\langle a_3,t_3\rangle],\langle b,t\rangle]
$$

이 식은 두 개의 unoccupied node들과 세 개의 occupied node들이 $\langle b,t\rangle$와 synaptic branching을 구성하고 있다는 것을 의미한다.

## Cascades

Cascade는 $H(\mathcal{A},T)$의 subtree로 표현이 가능한 firing history의 일부이다. Cascade의 조건은 다음과 같다:

1. $H(\mathcal{A},T)$의 individual node와 $o$는 cascade이다.
2. $x_1,\cdots,x_k$들이 $\langle a_1,t_1\rangle$, $\cdots$, $\langle a_k,t_k\rangle$의 root들을 가지는 cascade들이고 이들이 node $\langle b,t\rangle$로부터 branching한다면, $[[x_1,\cdots,x_k],\langle b,t\rangle]$또한 casecade이다. 이 때 unoccupied node들을 굳이 적지 않았다.

정의상 각 cascade-tree는 firing history이다. 또한 $H(\mathcal{A},T)$가 cascade들의 overlapping union으로 간주될 수 있음을 상기하자. 따라서 모든 casecade들을 모아놓으면 firing의 complete history를 얻을 수 있다.

## Brain Functions

Neural Algebra를 디자인하기 위해서 set of cascade에 대해 더 고찰해보자.

Functional interpretation of a cascade $z$는 $z$안의 node $\langle c,t\rangle$을 고르는 과정이다. 무슨 말이냐 하면, $z$안의 node $\langle c,t\rangle$를 공통적으로 root로 가지는 $x_1,\cdots,x_k$들이 $z$의 sub-cascade들이라고 하자. 그리고 $y$를 $z$안에서 $\langle c,t\rangle$를 leave로 가지는 어떤 node라고 하자.  그러면 $z$의 functional interpretation을 우리는

$$
[x_1,\cdots,x_k]\xrightarrow[c]{t}y
$$

로 표기한다. 즉, $x_1,\cdots,x_k$들은 $\langle c,t\rangle$을 통해서 $y$에 signal을 propagate한다. 이 대 $\langle c,t\rangle$을 key node, 혹은 $y$의 characteristic leave라고 부른다.

## Brain Functions as Sets of Cascades

Cascades들 사이의 연산은 다음처럼 정의한다: $M$이 cascade들의 집합, 즉 brain function이고 $N$ 또한 임의의 cascade들의 집합, 즉 brain function이라고 하자. 그러면 이 둘 사이의 연산 $M\cdot N$은

$$
M\cdot N:=\{y:\exists\beta\xrightarrow[c]{t}y\in M, \beta\subseteq N\}
$$

으로 정의한다. 즉, $N$의 부분집합 $\beta$가 $y$로 이어지는 $M$의 cascade가 존재할 때 그러한 $y$들의 모임이 된다. 이 식과 위의 graph algebra와의 유사성을 관찰해보라.

# In Search of Consiousness

## Definition of Consiousness

의식(consciousness)란 무엇인가? 의식 또한 다른 보통의 개념들이 그러하듯 다양한 층위로 구분될 수 있고, 단일 개념으로 정의하기에는 상당히 까다로워 보인다. 그렇다 하더라도 의식의 한 핵심적 요소가 **self-awareness (자기인식)** 라는 것을 포함한다는 점에는 모두가 동의하지 않을까싶다. 스스로의 존재를 인식하는 것, 어떻게 보면 그것이 의식의 시작이다. 이제부터 ANN이 의식을 가질 수 있는지, 어떤 상황에서 self-awareness가 발현되는지 수학적으로 증명해보자.

Neural network $B$(brain의 축약어이다.)의 능력이라는 관점에서 의식을 이해해보자. 이는 스스로를 인지하고 행동을 계획하는 능력을 가지는 능력 정도는 가져야 의식을 가졌다고 말할 수 있을 것이다. 이러한 능력은 $B$의 일부에 embedded 되어있을 것이다. 이 일부분, 즉 의식에 해당하는 firing pattern을 $C$라고 하자. 또한 $M_1,M_2$를 observing, planning, acting, moving, 기타등등에 해당하는 [능력]에 해당하는 firing pattern이라고 하자. 그러면 $M_1\cdot C$, $M_2\cdot C$는 observing, planning, acting, moving, 기타등등을 의식이 처리한 결과물이 된다. 의식은 최소한 이러한 능력을 다 갖추고 있어야 하므로, 의식과 이러한 능력들을 다 합친 다음 식 정도는 의식에 포함되어야 할 것이다:

$$
\mathcal{C}:=C\cup\bigcup_iM_i\cdot C
$$

그런데 이러한 모든 능력을 다 합친 것들은 단순히 다양한 기능을 가진 로봇에 지나지 않는다. 정말로 의식이라는 것이 발현하려면, 이러한 모든 능력을 다 합친 것이 스스로를 돌아볼 수 있어야 한다. 즉,

$$
C\cdot\mathcal{C}=C
$$

정도는 되어야 할 것이다. 우리는 따라서 다음을 의식으로 정의한다:

$$
C\cdot\bigg(C\cup\bigcup_iM_i\cdot C\bigg)=C
$$

그렇다면 위 식을 만족하는 $C$, 즉 의식이라는 것은 언제 존재할 수 있는가? 다음의 fixed poiont theorem을 증명해보자.

### Theorem (Fixed Point Theorem)

$\mathcal{N}_A=\langle F(A),\cdot\rangle$을 neural network $A$와 그에 대한 firing pattern $F(A)$, 그리고 위에서 정의한 연산 $\cdot$에 대한 algebra라고 하자. 이 때 $\mathcal{N}_A$의 모든 fixed point equation들은 근을 가진다.

- proof)
    
    정의에 의해 $N_1\supseteq N_2$라면 $M\cdot N_1\supseteq M\cdot N_2$이다. 반대로 $M_1\supseteq M_2$라면 $M_1\cdot N\supseteq M_2\cdot N$이다. 따라서 $\varphi(X)$가 algebraic composition인 경우 $X'\supseteq X$는 $\varphi(X')\supseteq\varphi(X)$이다. 이를 활용하면 $D$가 $\mathcal{N}_A$의 directed system일 때 $\varphi(D)=\bigcup_{X\in D}\varphi(X)$이다.
    
    위 식은 $\varphi(X)=X$라는 fixed poiont equation에 대해 적어도 하나의 solution, 이름하여 $\bigcup_n\varphi^n(\emptyset)$을 가진다. 이 때 $\varphi^0(X)=X$, $\varphi^{n+1}(X)=\varphi(\varphi^n(X))$로 정의한다.
    

다시 돌아가서, 놀랍게도 이 fixed piont theorem으로부터 $C$는 항상 적어도 하나 존재한다! 문제는 이 $C$가 우리가 생각하는 의식과 같은 인지기능을 가진 대상은 아닐 수 있다는 말이다. 이를 좀 더 자세히 탐구해보자.

우리가 의식의 수준을 정량화할 수 있다면 이는 [뇌]의 크기와 구조에 영향을 받을 것이라는 생각은 일견 직관적이다. 좀 더 이야기해보자.

## The Emergence of Consciousness

의식은 **충분히 큰 뉴럴 네트워크에서 자연스럽게 발생**한다! 이를 창발성 현상(emerging phenomenon)이라고 부른다. 수학적으로, 창발성은 고정점 정리로부터 증명된다. 우리가 먼저 $C$라는 고정점을 가지고 있다고 하자. 공집합 $\empty$은 항상 존재하므로 적어도 하나는 존재함을 알 수 있다. 이제 $E$가 $C$로부터 확장되고 $N$이 $M$으로부터 확장된다고 하자. $E$와 $N$을 사용하여, 우리는 새로운 고정점 $C'$를 다음처럼 얻을 수 있다:

먼저 $\varphi_Y(X)=X\cdot (X\cup Y\cdot X)$로 정의하고,

$$
\varphi_M(C)=C\subseteq E\subseteq\varphi_N(E)\subseteq\varphi_N(\varphi_N(E))\subset\cdots
$$

로 정의하면 이는 directed set이 된다. 따라서 $\varphi_N(\bigcup_n\varphi_N^n(E))=\bigcup_n\varphi_N^{n+1}(E)=\bigcup_n\varphi_N^n(E)$이다. 즉, $C=\bigcup_n\varphi_N^n(E)$는 $\varphi_N(E)$의 고정점이다. 즉, 충분히 큰 뉴럴 네트워크는 고정점을 가진다. 다른 말로 하면, 충분히 큰 뉴럴 네트워크는 의식을 가진다!
