
---
title: "의료인공지능의 윤리학, 그리고 정밀의료"
tags:
  - Medical AI
  - Medical Artificial Intelligence
  - AI Ethics
  - Medical AI Ethics
  - Medical Ethics
  - Precision Medicine

---



# 의료인공지능의 윤리, 그리고 정밀의료

# 이상과 현실

의료는 복잡다단하고, 기술이나 의술에만 기댈 수 없으며 사회와 소통하는 역동적인 학문입니다. 한 쪽을 방치하면 다른 쪽이 악화되고, 한 쪽을 잡으면 다른 쪽도 해결되는 등의 상상 밖의 일이 일어나곤 하죠. 예를 들어, 당뇨병을 예방하고 관리하는데 성공하면 국가적으로 실명하는 환자들이 줄어듭니다. 다른 예로는, 고혈압을 잘 관리하는 국가가 있다면 뇌출혈 발병률이 줄어들 것이죠. 지구 온난화가 가속화되면 말라리아가 퍼지고, 항공과 운수 산업의 발달은 코로나 바이러스를 전 세계로 퍼뜨렸습니다.

이처럼 복잡한 의학의 새로운 화두로 지난 10여년간 수없이 많은 연구가 지속된 신분야는 단언컨데 의료인공지능일 것입니다. 의료에 도입되는 모든 기술이 그러하듯, 인공지능 또한 예상치 못한 상황을 만들었고 만들고 있고, 인공지능 제품 또한 윤리적 문제를 피해갈 수 없습니다. 이 글에서는 의학에서 가장 권위있는 저널인 New England Journal of Medicine (NEJM)과 Journal of American Medical Association (JAMA)에 기고된 세 편의 글([글 1](https://www.nejm.org/doi/full/10.1056/NEJMms2200907), [글 2](https://jamanetwork.com/journals/jama/article-abstract/2800369), [글 3](https://jamanetwork.com/journals/jama/article-abstract/2800368))들과 다른 자료들을 몇 가지 참고하여 의료인공지능의 윤리에 관하여 고찰해보도록 합니다.

과학적 발전은 현대에 와서 가속화될 뿐 아니라 탈중앙화가 이루어지고 있습니다. 유전자 검사와 같은 기술들은 연구실에서 벗어나 규제를 통과하여 소비자들에게 직접 전달되고 있습니다. 디지털 치료제와 같은 기술들도 국가나 의사들이 처방을 내리는 것이 아닌, 소비자들이 직접 어플리케이션을 다운받아서 디지털을 통한 치료를 수행하고 있고요. 전통적으로 이어져 온 규제나 법적 이슈들은 더이상 이러한 현실을 마주하기에 최적의 수단이 아니게 되었습니다. 규제를 두 가지로 나누면

- 강한 규제 - 법적 규제나 통제와 같은 강제성이 부여되는 것
- 약한 규제 - 사회적 규범이나 가이드라인, 캠페인과 같은 강제성은 없지만 지키려고 노력하는 것

들이 있는데, 탈중앙화되는 과학기술은 약한 규제에 더 크게 의존할 수밖에 없습니다. 이러한 상황은 Collingridge 딜레마라는 딜레마를 야기할수 있습니다. Collingridge 딜레마란, 기술 발전 초창기에 근거가 부족해 예상되는 해악이나 부작용을 예측하지 못하기 때문에 정치적 의사결정이 규제냐 진흥이냐의 기로에서 더뎌지지만 한 번 그 해악성이 나타나고 나면 그 때는 정치적 의사결정을 하기에 너무 늦었다는 것이죠.

하지만 앞서 말한 기술의 해악은 모두에게 해를 끼치지는 않을 것입니다. 누군가는 과학기술의 발전으로 이득을 보거나 목숨을 건지지만, 또다른 누군가는 손해를 보거나 건강이 악화될 수도 있습니다. 심지어 다른 사람들은 아무런 이득이나 손해도 보지 못한 채 돈만 쓸 수 있으며, 가장 중요한 대부분의 인류는 그러한 과학기술을 접할 기회조차 없을 것이라는 것(개발도상국, 후진국의 인구들)은 큰 문제입니다. 즉, 과학은 평등하지만 동시에 과학은 평등하지 않습니다.

인공지능 이야기를 하면, 대규모 데이터셋이나 연구들은 대부분 백인 혹은 서양 사람들 기준으로 정비되어 있습니다. 폐암 검진에서 가장 유명한 데이터인 [National Lung Cancer Trail (NLST)](https://www.nejm.org/doi/pdf/10.1056/nejmoa1102873) 데이터만 하더라도 백인이 91%, 흑인이 5%이하, 아시아인이 2%남짓밖에 되지 않습니다. 위암(gastric cancer)은 서양에서는 거의 수술할 줄 아는 의사가 없을 정도로 적게 발병하지만 한국에서는 아주 큰 비율을 차지하는 암이라 국제 학회에서 큰 비중을 차지하지 못하는 것도 또다른 예시가 되겠지요.

이러한 맥락에서, 과학은 우리가 무엇을 할 수 있는지를 알려주고 가끔은 무엇이 안전한지를 알려주지만, 우리가 무엇을 해야 하고 어떻게 해야 하는지에 관한 것은 과학만으로 해결되지 않습니다.

> Science can tell us whether we can do something and often whether it is safe, but the questions of whether we ought to and how we should proceed are not solely scientific ones.
> 

DHHS (Department of Health and Human Services; 미국 보건복지부) 도 이러한 문제점을 인식하고 있었고 2022년 7월 이러한 인종적 차별에 맞서싸울 것이라는 [글을 기고](https://www.hhs.gov/civil-rights/for-providers/laws-regulations-guidance/regulatory-initiatives/1557-fact-sheet/index.html)하기도 했습니다. 실제로 많은 임상 알고리즘들은 특정 인종에만 맞추어져 있으며 예시를 들자면 알츠하이머를 진단하는 머신러닝 알고리즘이 특정 악센트를 구사하는 집단에서는 다른 결과를 낸다는 것이나, 소득이 낮은 집단은 병원에 *노쇼(no-show)*를 할 가능성이 높기 때문에 특정 알고리즘은 중위 소득 이상에서만 결과를 잘 낸다는 [글](https://openyls.law.yale.edu/handle/20.500.13051/5964)이 그 예시가 될 수 있을 것입니다. 따라서 DHHS는 FDA (Food and Drug Administration) 에 더 꼼꼼하고 세밀한 데이터에 대한 기준을 세울 것이라는 것이 바로 유추가 가능해집니다.

ACA (Affordable Care Act; 환자보호 및 부담적정보험법, a.k.a. 오바마케어)의 section 1557은 환자의 인종적, 연령적, 장애 정보에 기반한 어떠한 차별도 금지하고 있습니다. 이 글에서 자세하게 다루지는 않지만 ACA의 section 1557을 위반하면 보건복지부의 처벌을 비롯한 다양한 맥락에서 제제가 들어가기까지 합니다. 심지어 환자들은 차별을 당한다면 해당 기관에 소송을 걸 수 있는 권리까지 있습니다.

바이든 정부에서는 이 section 1557을 업데이트하려는 시도까지 했습니다. 특히나 인상깊은 부분은 92.210 조항인데요, 이 조항은 다음처럼 기술합니다:

> … a covered entity must not discriminate against any individual on the basis of race, color, national origin, sex, age, or disability through the use of clinical algorithms in its decision-making …
> 

이 조항의 실질적 의미는 디지털 치료제를 비롯한 새로이 개발되는 clinical algorithm들이 차별적이지 않아야 한다, 즉 학습 시점부터 데이터에 대한 bias가 끼어있지 않아야 하거나 이를 극복하기 위해 노력해야 한다는 것을 함의한다고 해석해도 무방합니다. 다만 이는 clinical algorithm을 사용하는 것을 훼방하거나 막으려는 조항이 아님을 분명히 밝히고 있는데요, 불행히도 이 조항의 의도대로 의료계가 돌아갈 것 같지는 않습니다. 특히나 인공지능이나 머신러닝과 같은 복잡한 알고리즘은 소위 말하는 블랙박스로 간주되기 때문에 내부 인자 하나하나가 어떻게 돌아가는지 알기는 사실상 불가능하고, 따라서 어떤 인자가 차별을 야기하는지, 따라서 삭제하거나 변형시켜야 하는지 아는 것은 어불성설이기 때문입니다.

따라서 DHHS의 해당 조항은 두 가지 입장을 나눠서 보는 것이 타당한데요,

1. 첫 번째로는 머신러닝이나 딥러닝과 같은 복잡한 기술에 대해서는 차별을 제거하기 위해 가능한 최선의 노력을 하라는 말에 가깝고
2. 머신러닝이나 딥러닝이 아닌 다른 임상적 알고리즘들, 예를 들어 사구체여과율 추정과 같은 알고리즘에 있어서는 소외되는 집단이 없도록 최선을 다하라는 말이 되겠습니다.

인공지능이나 머신러닝에 대해서 조금 더 이야기해보면 바로 위에서 이야기한 1번의 측면은 데이터, 혹은 학습의 측면입니다. 따라서 DHHS는 외부 cohort 타당도 검증을 할 때

- 언제 쓸 수 있고 어떻게만 써야 하는지,
- 어떤 집단에 대해서 검증을 수행했는지,
- 가능한 다양한 집단에 대해 검증하며 숨어있는 bias를 찾아내려고 노력했는지,

와 같은 것들을 잘 고민하라고 이야기하고 있습니다. 역시나 이것은 이상에 가깝다고 보아야 합니다. 거대 병원, 혹은 다기관 연구가 가능한 연구 그룹 혹은 회사가 아닌 이상에야 실제 환자들은 병원마다 bias가 될 것이 뻔하기 때문입니다. 엄포가 무섭지만, DHHS가 이러한 규제 혹은 윤리강령을 위반하는 제품, 연구들에 얼마나 큰 패널티를 줄지는 아무도 모릅니다.

임상 의사들에게 신기술을 쓰게 장려하는 것은 의학의 발전을 위해 필수적이지만 동시에 이러한 차별성을 경계하는 것, 이 두 가지는 양날의 검입니다. 또한 DHHS가 규제하겠다고 했기 때문에 DHHS 자신들이 언제 규제하고 언제 규제하지 않을지 리더십을 제시하는 것이 중요해지겠죠. 이를 위한 DHHS의 역할은 다음 정도는 포함되어야 할 것입니다.

1. 의료 전문가들에 대한 safe harbor (특정 조건, 상황 하에서는 법적 책임이나 의무에 대한 위반으로 야기되는 벌칙을 피할 수 있는 제도적 장치) 의 마련
    1. 단순히 AMA (American Medical Association; 미국의사협회) 의 가이드라인이나 플로우차트를 따르기만 한다면 의학 발전은 없을 것입니다. 따라서 SaMD (Software as a Medical Device)와 같은 준칙을 따르면 92.210조항을 피해 갈 수 있는 것과 같은 제도적 회피를 제공해야 한다는 말입니다.
2. DHHS는 FDA와 긴밀히 협력하여 임상 알고리즘의 최적의 검증 수단을 찾아야 합니다. 
    1. FDA는 의료기기를 통제하기 때문에 소프트웨어도 당연히 규제 대상에 포함됩니다. 따라서 FDA는 510(k)와 같은 규제에 대해서 의료 소프트웨어 기기 회사들, 특히 AI나 머신러닝을 통해 진단 보조를 하려는 회사들에게 가이드라인을 제시해야 할 것입니다.
    2. DHHS는 반면 임상 의사들에게 어떻게 해야 숨어있는 bias를 찾아낼 수 있을지 그에 대한 방법론 교육 및 가이드라인을 제시해야 할 것입니다.

문제는 이는 biased된 알고리즘이 차별을 하는 것을 막기 위한 필요조건밖에 되지 못한다는 것이고, CDSS (Clinical Decision Support Software)과 같은 소프트웨어는 FDA의 규제 범위 바깥에 있기 때문에 이러한 노력이 물거품이 될 가능성도 있습니다. 이상적인 말을 하자면, 종래에는 이러한 규제 기관 및 규제 정책들이 다 갈아엎어져야 한다는 말까지도 극단적으로 해 볼 수 있겠지요.

# 그리고 정밀 의료

폐암을 생각해 봅시다. 폐암은 다 똑같을 것만 같지만 소세포암, 비소세포암으로 구분되고 비소세포암은 편평상피암, 선암, 거대세포암으로 구분되며 이들은 분자나 유전자 돌연변이에 따라 수많은 종으로 구분됩니다. 인류가 이를 처음부터 알지는 않았을 것입니다. 의학이 발전하며 폐암을 세분화하게 되고 이러한 세분화가 진단과 치료에 영향을 주어 비소세포암과 소세포암의 치료가 달라지는 등 점점 복잡해지고 다양한 과학적 발견들이 진행되고 있습니다.

현대 의학은 근거 중심 의학(EBM; Evidence-Based medicine)이라고 불립니다. 통계적 방법론을 동원하여 어떤 약, 치료가 좋다는 것을 과학적으로 입증하고 이것을 바탕으로 표준 치료 방침이 수행되는 것이지요. 이 과정은 이제 의학 연구의 표준으로 자리잡았습니다. 사람들은 그 다음 의학이 나아가야 할 방향으로 눈을 돌리기 시작했고, 그것이 바로 정밀 의료(precision medicine)입니다.

사실 정밀 의료는 과거부터 있었습니다. 아니, 사실은 의학 통째로가 정밀 의료로 나아가고 있었다고 해도 과언이 아니지요. 비슷한 증상을 보이는 환자들을 묶어 하나의 질환으로 생각했다가, 시대가 지나고 의학이 발전하며 비슷한 증상이지만 원인이 다른 환자들을 구분할 수 있는 방법론 및 진단기준이 생기고, 그것이 다시 또 세분화되고, 세분화되고, 세분화되고…를 반복하는 것이지요. 이러한 정밀 의료가 의료인공지능의 윤리와 어떤 관련이 있길래 저는 정밀의료를 말하는 것일까요?

바로 bias가 없는 완벽한 모델의 탄생은 정밀의료의 궁극적 목적과 맞닿아있기 때문입니다. 만약 백인 데이터에 대해서 학습했던 모델을 흑인, 황인에게 적용하여 잘못된 결과를 얻었다면, 이 모델 혹은 진단기준 혹은 치료는 [인류]라는 거대한 그룹을 세분화하지 못한 정밀의료의 반대 지점에 서있는 모델이기 때문입니다. 하지만 정말로 압도적으로 다양한 데이터에 대해서 학습되었거나, 다양한 인종 혹은 남여노소, 정상인을 비롯한 수많은 질환을 가진 데이터에 대해서 임상적인 검증이 된 모델이 있다면 bias는 적을 것이고 동시에 개개인에 대한 상황 맞춤형 모델이 될 것이기 때문에 정밀의료 바로 그 자체를 구현한 것이 되는 셈일 것이기 때문이죠.

여기까지 상당히 이상적이고 관념적인 이야기였습니다. 의학의 발전은 의학의 말소에 있습니다. 의학의 궁극적 목표인 인류의 무병, 불로장생에 대해 만약 모든 사람이 무병, 불로장생한다면 의학이 더 이상 필요가 없어지는 날이 올 것이기 때문이죠. 그렇다고 의학이 의미없다고 주장하는 사람은 이 세상에 없을 것입니다. 자신의 소멸을 위해 끊임없이 노력하는 의학은 실제로 사람들을 살리고 생명을 연장시켜주니까요.

이처럼 어찌 생각하면 순전히 무지개만 좇는 인공지능의 윤리, 혹은 그와 동치일지도 모르는 정밀의료는 사실상 구현이 불가능할 것입니다. 중요한 것은 달성 가능하냐가 아니라, 우리가 어디까지 노력했냐가 아닐까 싶습니다. 위대한 천문학자 수브라마니안 찬드라세카르(Subrahmanyan Chandrasekhar)의 장례식에서 에드워드 윌슨(Edward O.Wilson)이 했던 말을 인용하며 글을 마치겠습니다.

> Let us see how high we can fly before the sun melts the wax in our wings.
태양빛이 우리 날개의 밀랍을 녹이기 전 까지 어디까지 날 수 있는지 한 번 날아나 보자(크레타 섬을 탈출하는 이카루스 신화를 언급하며).
>
