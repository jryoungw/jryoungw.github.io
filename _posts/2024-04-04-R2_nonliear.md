---
title: "R2 score - Nonliear model이어도 괜찮아"
tags:
  - Statistics
tags:
  - AI
  - Artificial Intelligence
  - Statistics
  - R2 score
  - Medicine
---
# R square - Nonlinear model이어도 괜찮아

글이 깨지는 경우 [링크](https://jryoungw.notion.site/R-square-Nonlinear-model-0a293bfd1ff941b1bd08a1ad3e4c876e?pvs=4)에서 보시면 됩니다.

# Introduction

R square value는 일반적으로 linear model에서 적절하고, nonlinear model에서는 R square를 쓰는 것이 적절하지 않다는 주장을 많이 보곤 한다. 하지만, 본 글에서는 nonlinear model에서도 R square를 쓸 수 있다는 것을 논증하고자 한다.

# R square의 정의

$\{y_i\}_{i=1}^N$이라는 정답 데이터와 $\{\hat{y}_i\}_{i=1}^N$이라는 예측 데이터가 있다고 할 때

$$
R^2=1-\frac{SS_{res}}{SS_{tot}}
$$

가 R square $R^2$의 정의인데, 이 때 $\overline{y}=\frac{1}{N}\sum_{i=1}^Ny_i$라고 하면 total sum of squares $SS_{tot}$는

$$
SS_{tot}=\frac{1}{N}\sum_{i=1}^N(y_i-\overline{y})^2
$$

이고 residual sum of squares $SS_{res}$는

$$
SS_{res}=\frac{1}{N}\sum_{i=1}^N(y_i-\hat{y}_i)^2
$$

이 된다.

만약 모든 $i$에 대해 $y_i=\hat{y}_i$였다면 $SS_{res}$는 0이 되므로 완벽한 모델이 될 것이고, 모든 $i$에 대해 $\hat{y}_i=\overline{y}$인 소위 baseline 모델에 대해서는 정의에 의해 $R^2=0$이 나올 것이다.

# 왜 nonlinear model에서 쓰면 안된다는 것인가?

구글에 R square nonliear model이라고 검색을 해 보면 많은 글들에서 ([블로그 1](https://statisticsbyjim.com/regression/r-squared-invalid-nonlinear-regression/), [블로그 2](https://blog.minitab.com/en/adventures-in-statistics-2/why-is-there-no-r-squared-for-nonlinear-regression)) 같은 논증으로 R square를 nonlinear model에 쓰지 말라고 한다. 이는 

- Total varaince = Explained variance + Error variance

라는 r square의 가정이 깨지기 때문이라는 것을 근거로 든다. 정말 그러한지 수식을 통해 살펴보면

$$
SS_{tot}=SS_{res}+SS_{err}
$$

이라는 것인데, $SS_{tot}$에 대해 식을 정리하기 위해 두 가지 가정이 필요하다. $y_i=\hat{y}_i+e_i$로 error term을 정의하면,

- $\sum e_i=0$.
- $\sum e_i\hat{y}_i=0$.
    - 이는 $\overline{e}=\frac{1}{N}\sum e_i=0$이었으므로
        
        $$
        \sum e_i\hat{y}_i=\sum (e_i-0)\hat{y}_i-\overline{y}\cdot0=\sum(e_i-\overline{e})(\hat{y}_i-\overline{y})=0
        $$
        
        이라는 말과 동치이기 때문에 normal equation을 통해 나온 error term들이 sample과 독립이라고 가정하면 해결된다. 단, 이 조건이 독립이라는 조건이 아니라 공분산이 0인 상관관계가 없다는 조건임에 주의하자.
        

이로부터

$$
\begin{align*}SS_{tot}&=\frac{1}{N}\sum_{i=1}^N(y_i-\overline{y})^2\\
&=\frac{1}{N}\sum_{i=1}^N((\hat{y}_i+e_i)-\overline{y})^2\\
&=\frac{1}{N}\sum_{i=1}^N(e_i+(\hat{y}_i-\overline{y}))^2\\
&=\frac{1}{N}\sum_{i=1}^Ne_i^2+\frac{1}{N}\sum_{i=1}^N2\cdot e_i(\hat{y_i}-\overline{y})+\frac{1}{N}\sum_{i=1}^N(\hat{y}_i-\overline{y})^2\\
&=\frac{1}{N}\sum_{i=1}^Ne_i^2+\frac{2}{N}\sum_{i=1}^Ne_i\hat{y}_i-\frac{2}{N}\overline{y}\sum_{i=1}^Ne_i+\frac{1}{N}\sum_{i=1}^N(\hat{y}_i-\overline{y})^2\\
&=SS_{err}+0-0+SS_{res}\\
&=SS_{res}+SS_{err}
\end{align*}
$$

이 된다.

위 식을 맨 아래에서부터 거꾸로 읽어보아도 $SS_{tot}=SS_{res}+SS_{err}$이 성립하기 위한 조건은 위에서 한 두 가지 가정 뿐이다. 그렇다면 위 두 가지 가정을 만족시키면 $R^2$를 쓸 수 있다는 말이 되지 않을까?

# R square score을 nonlinear model에서 정당화하기

위 글에서 살펴보았듯, R square를 구하는 것은 모델의 종류와는 상관이 없고 어떤 가정이 들어가느냐에 의존한다. linear regression에서 normal equation의 가정으로부터 다음 조건들이 유도되기에:

- $\sum e_i=0$.
- $\sum e_i\hat{y}_i=0$.

R square score를 nonlinear model에 적절하게 사용하고 싶다면 위 두 가정을 만족함만 보여도 충분하다.

따라서, 본 글에서 제안하는 방법은 R square를 구할 때 두 가지 plot을 함께 그리라는 것이다.

1. 일반적인 Correlation plot
2. 추가적인 Bland-Altman plot

이는 2번의 Bland-Altman plot를 통하여 첫 번째 가정 $\sum e_i=0$을 확인할 수 있기 때문이다. 두 번째 가정을 확인하는 것은 단순히 예측값인 $\hat{y}_i$들과 $e_i$들을 곱해서 더한 것이 $0$과 차이가 있는지 귀무가설을 세워 검증하기만 하면 되므로 큰 어려움이 없다는 것을 알 수 있다.

# 세줄요약

따라서 요약하면,

1. Correlation plot과 Bland-Altman plot을 그려서 real value와 prediction value의 평균의 차이가 없다는 것을 보이고,
2. error term과 prediction term을 곱한 항들의 합이 0이 됨을 보이면

R square method는 어떤 모델에서나 쓸 수 있다는 결론을 얻는다.
